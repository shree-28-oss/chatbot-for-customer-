from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt

# Define the parameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize the model
rf_model = RandomForestRegressor(random_state=42)

# Perform GridSearchCV
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best model
best_rf_model = grid_search.best_estimator_
print(f"Best Hyperparameters: {grid_search.best_params_}")

# Train the best model on the entire training set
best_rf_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_optimized = best_rf_model.predict(X_test)

# Evaluate the optimized model
mse_optimized = mean_squared_error(y_test, y_pred_optimized)
r2_optimized = r2_score(y_test, y_pred_optimized)
mae_optimized = mean_absolute_error(y_test, y_pred_optimized)
print(f"Optimized Model - Mean Squared Error (MSE): {mse_optimized}")
print(f"Optimized Model - R-squared (R2): {r2_optimized}")
print(f"Optimized Model - Mean Absolute Error (MAE): {mae_optimized}")
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_optimized, alpha=0.5, color='blue')
plt.xlabel("Actual Review Rating")
plt.ylabel("Predicted Review Rating")
plt.title("Actual vs. Predicted Review Ratings (Optimized Model)")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Add a diagonal line
plt.show()
